# Section 6.1 Case Study MNIST
library(dslabs)
library(tidyverse)
mnist <- read_mnist()

names(mnist)
dim(mnist$train$images)

class(mnist$train$labels)
table(mnist$train$labels)

# sample 10K rows from the training set and 1L rows from the test set
set.seed(123)
index <- sample(nrow(mnist$train$images), 10000)
x <- mnist$train$images[index,]
y <- factor(mnist$train$labels[index])

index <- sample(nrow(mnist$test$images), 1000)
x_test <- mnist$test$images[index,]
y_test <- mnist$test$labels[index]

image(matrix(1:784 %in% x , 28, 28))

# section 6.2 preprocessing MNIST data
library(matrixStats)
sds <- colSds(x)
qplot(sds, bins = 256, color = I("black"))

library(caret)
nzv <- nearZeroVar(x)
image(matrix(1:784 %in% nzv, 28, 28))

col_index <- setdiff(1:ncol(x), nzv)
length(col_index)

# section 6.3 model fitting for mnist data
colnames(x) <- 1: ncol(mnist$train$images)
colnames(x_test) <- colnames(x)

control <- trainControl(method = "cv", number = 10, p = 0.9)
train_knn <- train(x[,col_index], y,
                   method = "knn", 
                   tuneGrid = data.frame(k = c(1,3,5,7)), 
                   trControl = control)
ggplot(train_knn)

# sample smaller set to reduce running time
n <- 1000
b <- 2
index <- sample(nrow(x),n)
control <- trainControl(method = "cv", number = b, p = 0.9)
train_knn <- train(x[index, col_index], y[index],
                   method = "knn", 
                   tuneGrid = data.frame(k=c(3,5,7)),
                   trControl = control)
ggplot(train_knn)

# run for knn model
fit_knn <- knn3(x[ ,col_index], y, k=3)

y_hat_knn <- predict(fit_knn, 
                     x_test[, col_index], 
                     type = "class")
cm <- confusionMatrix(y_hat_knn, factor(y_test))
cm$overall["Accuracy"]

cm$byClass[,1:2]

# Rborost code
library(Rborist)
# small version code first
n <- 500
b <- 2
index <- sample(nrow(x),n)
control <- trainControl(method = "cv", number = b, p = 0.8)
grid <- expand.grid(minNode = c(1,5), predFixed = c(10,15,25,35,50))
train_rf <- train(x[index , col_index], y[index],
                  method = "Rborist",
                  nTree = 50, 
                  trControl = control, 
                  tuneGrid = grid,
                  nSamp = 5000)
ggplot(train_rf)
train_rf$bestTune

fit_rf <- Rborist(x[index, col_index], y[index],
                  nTree = 1000,
                  minNode = train_rf$bestTune$minNode,
                  predFixed = train_rf$bestTune$predFixed)

y_hat_rf <- factor(levels(y)[predict(fit_rf, x_test[ ,col_index])$yPred])
cm <- confusionMatrix(y_hat_rf, y_test)
cm$overall["Accuracy"]

# main code
control <- trainControl(method = "cv", number = 5, p = 0.8)
grid <- expand.grid(minNode = c(1,5), predFixed = c(10,15,25,35,50))
train_rf <- train(x[ , col_index], y,
                  method = "Rborist",
                  nTree = 50, 
                  trControl = control, 
                  tuneGrid = grid,
                  nSamp = 5000)
ggplot(train_rf)
train_rf$bestTune

fit_rf <- Rborist(x[ , col_index], y,
                  nTree = 1000,
                  minNode = train_rf$bestTune$minNode,
                  predFixed = train_rf$bestTune$predFixed)

y_hat_rf <- factor(levels(y)[predict(fit_rf, 
                                   x_test[, col_index])$yPred])
cm <- confusionMatrix(y_hat_rf, y_test)
cm$overall["Accuracy"]

rafalib::mypar(3,4)
for(i in 1:12){
  image(matrix(x_test[i, ], 28, 28)[, 28:1],
        main = paste("Our prediction:", y_hat_rf[i]),
        xaxt = "n", yaxt = "n")
}


